\part{Implémentation}
\thispagestyle{part}
\parttoc
%\thispagestyle{part}
 
  %\chapter{Considérations générales}
  %\section{Objectifs}
  %Pour rappel, l'objectif est de fournir une sonde ayant répondant à un certain nombre de critères:
  %\begin{itemize}
  %  \item Elle doit permettre d'analyser du code \Python
  %  \item Elle doit communiquer avec l'\gls{agent} en utilisant un protocole propre à \Blackfire
  %  \item Elle doit générer le \gls{graphe d'appels} du programme
  %  \item Elle doit collecter des métriques sur le temps passé dans chaque fonction/méthode
  %  \item L'\gls{overhead} induit par la sonde doit être minimal
  %  \item L'instrumentation du code doit être automatique
  %  \item Conformément au protocole, la sonde ne doit déclencher l'analyse que à la demande
  %\end{itemize}

%  \section{Travail effectué}
%  Le travail effectué a donné lieu à deux implémentations de la sonde. Une première écrite uniquement en Python servant essentiellement de preuve de faisabilité et ayant certains problèmes de performance. Et une seconde reprenant le travail effectué sur la première implémentation mais avec les parties critiques, d'un point de vue performances, écrites directement en \C.
  
La sonde est découpée en trois grandes parties : trois modules correspondant aux trois rôles principaux de la sonde, à savoir :
\begin{itemize}
\item \textbf{Instrumentation} \emph{automatique} : le module \mintinline{python}{blackfire} définit l'interface publique qui sera exposée à l'utilisateur, à savoir les différents points d'entrée permettant de lancer l'analyse du code.
\item \textbf{Intégration} \emph{avec Blackfire} : le module \mintinline{python}{blackfire.probe} définit la classe \\\mintinline{python}{BlackfireProbe} qui implémente le protocole utilisé pour communiquer avec l'agent \Blackfire. Cette classe est instanciée par les différents points d'entrée en un objet qui représente ainsi la sonde actuellement utilisée. La classe \mintinline{python}{BlackfireProbe} définie aussi une interface qui permet au développeur, si l'objet est exposé, de contrôler plus finement les parties du code qui sont analysées.
\item \textbf{Collecte} \emph{des données} : le module \mintinline{python}{blackfire.profiler} définit la classe \mintinline{python}{Profiler} qui est en charge de collecter les données qui formeront le profil (\gls{métriques} et \gls{graphe d'appels}).
\end{itemize}

\begin{note}[Python 3]
\Python 3 a apporté de grands changements au langage avec, par exemple, un support par défaut de l'UTF-8, mais a au passage cassé la rétro-compatibilité avec \Python 2. Cette cassure étant très importante\footnote{Voir annexe \vref{app:compat-py3} pour plus de détails}, le taux d'adoption de \Python 3 est assez faible mais en constante progression. Il est donc important pour \Blackfire de supporter les deux versions.
\end{note}
% TODO note sur cPython vs Pypy and others

  \chapter[Instrumentation]{Instrumentation automatique}
\Blackfire est un outil destiné à être utilisé aussi bien lors du développement que sur des sites en production. Cela implique que, même si l'\gls{overhead} induit par la sonde est très faible, la sonde ne doit être activée que si un profil a été demandé afin d'éviter de générer des milliers (voir des millions) de profils inutilement.

Cette partie a donc pour rôle de s'assurer qu'un profil a été demandé et ensuite de brancher dans le \gls{code utilisateur} la partie qui s'occupe de l'intégration avec le reste de l'outil. Néanmoins cette tâche doit être exécutée de manière automatique ou alors avec le minimum de modification dans le code utilisateur.

Pour cela trois principaux cas de figures sont à considérer :
\begin{itemize}
\item L'instrumentation automatique d'un programme en ligne de commande (\gls{CLI})
\item L'instrumentation automatique d'une application \gls{WSGI} (application web)
\item L'instrumentation manuelle par le développeur
\end{itemize}

\section[Programme CLI]{Instrumentation automatique d'un programme CLI}
\label{sec:instru-pythonpath}
On considère ici un programme analysé via l'utilisation de l'outil en ligne de commande. Dans ce cas il est possible d'utiliser le module \verb|site|\footnote{\url{https://docs.python.org/2/library/site.html}} de \Python afin d'instrumenter le programme automatiquement, et ceci sans aucune modification.

Cela est possible grâce au comportement particulier du module \verb|site|. En effet, il s'agit d'un module qui est importé (et donc exécuté) automatiquement lors du lancement d'un programme \Python. Ce module a pour rôle de rechercher un autre module nommé \verb|sitecustomize| dans les différents dossiers référencés par la variable d'environnement \verb|PYTHONPATH|\footnote{La variable d'environnement \verb?PYTHONPATH? est vide par défaut}, puis de le charger et de l'exécuter.

\begin{listing}[H]
\caption{Exemple d'analyse d'un programme en ligne de commande}
\begin{bashcode}
 $ $ PYTHONPATH='/chemin/vers/blackfire/bootstrap/sitecustomize.py' blackfire run python mon-programme.py
\end{bashcode}
\end{listing}

Le module \verb|sitecustomize| est très simple : il regarde si la variable d'environnement \verb|BLACKFIRE_QUERY| est présente\footnote{La variable d'environnement est définie lors de l'utilisation de la commande \verb|blackfire run|, son contenu sera précisé plus tard - voir section \vref{subsec:BlackfireQuery}} et, si c'est le cas, branche \Blackfire en passant la main à la sonde à proprement parler \footnote{Voir chapitre \vref{chap:integration}}.

\begin{listing}[H]
\caption{Instrumentation automatique d'un programme en ligne de commande}
\pythonfile{codes/probe/blackfire/bootstrap/sitecustomize.py}
\end{listing}

\begin{note}
À l'avenir, on peut imaginer que l'outil en ligne de commande \Blackfire va configurer automatiquement la variable d'environnement \verb|PYTHONPATH| de l'utilisateur, ce qui permettrait de simplifier la commande précédente.
\end{note}

\section[Application WSGI]{Instrumentation automatique d'une application WSGI}
On considère ici une application web utilisant la spécification WSGI\footnote{\url{https://docs.python.org/2/library/wsgiref.html}}. Dans ce cas il est nécessaire de décorer le point d'entrée\footnote{Il s'agit de l'objet (function ou variable) qui a le nom \verb|application| dans le contexte du module renseigné auprès du serveur WSGI} de l'application par un middleware WSGI qui va se charger de vérifier la présence de l'en-tête \verb|X-Blackfire-Query|\footnoe{Cet en-tête est défini lorsque le compagnon ou la commande \verb|blackfire curl| est utilisé - voir section \vref{subsec:BlackfireQuery})} et d'activer \Blackfire le cas échéant. Ce middleware a aussi la charge de récupérer le code HTTP de la réponse (requis par le protocole) et de définir la \emph{Response Line} qui est envoyée au compagnon.

Ce middleware a été implémenté dans la classe \verb|blackfire.WSGI_wrapper|, et le décorateur \verb|blackfire.wsgi_application| permet d'en simplifier l'utilisation lorsque que le point d'entrée est une fonction\footnote{Voir Annexe \vref{app:decorateurwsgi} pour le code du décorateur}.

\begin{listing}[H]
\caption{Exemple d'utilisation du décorateur WSGI}
\pythonfile{codes/probe/test_wsgi.py}
\end{listing}

%\section{Instrumentation manuelle}

% TODO Conserver cette section ? si oui la rédiger

%\begin{listing}[H]
%\caption{Instrumentation effective du code}
%\pythonfile[firstline=9]{codes/probe/blackfire/config.py}
%\end{listing}

  \chapter[Intégration]{Intégration avec Blackfire}
  \label{chap:integration}
% Schéma pour montrer où on se situe dans l'archi/workflow ?
La sonde travaille en tandem avec l'agent, : quand la première collecte les données, le second les traite et les envoie à l'API. Ce ci implique qu'ils communiquer l'un avec l'autre, ce qu'ils font au travers d'un protocole dédié\footnote{Voir section \vref{sec:BlackfireProtocol}}.


%	\section{Protocole}
% Schéma de l'architecture/protocole complet tout en gris excepté la partie qui nous concerne
%	\subsection{La requête}
%    \label{subsec:BlackfireQuery}
  
  \chapter[Collecte]{Collecte des données}
Le rôle principal de la sonde, avant de s'intégrer avec le reste de \Blackfire, est de collecter des données, des métriques sur le code.

La sonde étant exécutée en même temps que le code utilisateur ses performances sont cruciales. Il est donc important de minimiser son impact, aussi bien sur les performances (les temps) que sur la consommation mémoire. Pour cette raison il a été décidé de l'implémenter en \C\footnote{Une première version a été implémentée en \Python afin de servir de preuve de faisabilité, et l'impact était très important ; le temps d'exécution était souvent doublé, parfois même décuplé.}.

  \section{Fonctionnement général}
La méthode utilisée pour instrumenter le code \Python est la même que celle utilisée par \emph{Yappi}\footnote{Voir section \vref{subsec:yappi}}, dont sont issus ou inspirés certains éléments de l'implémentation actuelle. À savoir l'utilisation de la méthode \verb|sys.setprofiler()| qui permet de définir une fonction de rappel appelée à chaque fois que l'interpréteur entre ou sort d'une fonction.

Dans l'implémentation actuelle, la fonction \C \verb|_blackfire_callback| est enregistrée en tant que fonction de rappel et est donc appelée à chaque fois que l'un des événements\footnote{Les événements sont toujours déclenchés avant l'exécution du code par l'interpréteur} suivants intervient :
\begin{itemize}
\item \verb|PyTrace_CALL| : exécution d'une fonction écrite en \Python
\item \verb|PyTrace_RETURN| : fin d'une fonction \Python
\item \verb|PyTrace_EXCEPTION| : fin d'une fonction \Python avec exception
\item \verb|PyTrace_C_CALL| : exécution d'une fonction écrite en \C
\item \verb|PyTrace_C_RETURN| : fin d'une fonction \C
\item \verb|PyTrace_C_EXCEPTION| : fin d'une fonction \C avec exception
\end{itemize}

Le rôle de cette fonction de rappel est double. D'un côté c'est elle qui va lancer l'analyse des différents événements, et c'est donc à partir d'elle que tout le travail de collecte de données va être effectué. De l'autre elle s'assure que les exceptions lancées par le code utilisateur sont conservées et ne sont pas écrasées si des problèmes surviennent pendant le traitement de l'événement en question\footnote{L'action de \Blackfire doit impacter aussi peu que possible le code utilisateur et cela concerne aussi la gestion des erreurs : la sonde doit être capable, autant que possible, de traiter ses propres erreurs}.

Les appels \C et les appels \Python sont traités de manière identique. Néanmoins il y a quelques différences d'implémentation car certaines données ne sont pas collectées de la même manière. De même, aucune différence n'est faite entre les fins de fonction avec et sans exception. Ainsi les six événements précédents sont répartis en deux groupes : \emph{Début} et \emph{Fin} de fonction.

L'idée est donc d'utiliser ces événements pour maintenir la \gls{pile d'appels} du programme et remplir le \gls{graphe d'appels} au fur et à mesure avec les métriques correspondantes.

  \section{Gestion du graphe d'appels}
  \label{sec:gestion-graph-appels}
La \gls{pile d'appels} du programme est construite à l'aide de l'objet \verb|frame|\footnote{Cet objet représente le contexte d'exécution de la fonction et contient donc toutes les informations sur le code exécuté. Pour plus de détails : \url{https://docs.python.org/2/library/inspect.html}} envoyé à la fonction de rappel. À chaque événement de type \emph{entrée de fonction} on identifie l'appel de fonction et on l'ajoute dans la pile.
  
Cet appel est identifié\footnote{Voir annexe \vref{app:pile_struct} pour les structures de données} par ses arguments si ceux-ci sont collectés\footnote{Voir section \vref{sec:fnargs}} et par la méthode qui est appelée, elle-même identifiée par son module, sa classe et son nom. 

À cet appel de fonction on associe ensuite une série de métriques qui reflètent l'état du système au moment où la fonction est appelée. Ainsi sont mesurés à ce moment la date en microsecondes, le temps système écoulé ou encore le nombre d'opcodes exécutés depuis le début du programme.

\begin{note}[Importation de la pile courante]
Lors de l'appel à \verb|start|, la pile d'exécution courante est importée afin de tout le temps avoir des couples appelant/appelé corrects et d'éviter de se retrouver avec des appels de fonctions orphelins (sans appelant). Pour cela on parcourt la pile courante en sens inverse (donc en partant du contexte le plus ancien) et on simule une entrée de fonction pour chaque contexte.
\end{note}

\begin{note}[Gestion des appels récursifs]
Afin d'éviter de générer des graphes cycliques\footnote{C'est à dire un graphe où les appels récursifs génèrent des cycles}, un appel de fonction est aussi identifié par son niveau de récursivité. Celui-ci correspond au nombre de fois où la fonction appelée est déjà présente dans la pile. S'il est différent de 1 il sera ajouté au nom de la fonction dans le graphe sous la forme \verb|@<niv. rec.>|.
\end{note}

\begin{note}[Performances]
Il est important de contrôler l'utilisation de la mémoire\footnote{Voir section \vref{sec:performances} pour plus de détails sur la gestion des performances}, afin d'éviter que celle-ci augmente indéfiniment lors de l'analyse d'un gros programme. Pour cela les méthodes ne sont identifiées qu'une seule fois puis mises en cache dans une table de hachage afin d'être réutilisées, par la même occasion cela permet de ne pas répéter les même calculs.
\end{note}

\subsection{Identification de la méthode appelée - Appel Python}
\label{ident-python}
Lors d'un appel \Python (appel d'une fonction écrite en \Python) le \emph{\gls{contexte d'exécution}} envoyé à la fonction de rappel correspond à celui de la fonction qui va être exécutée.

\paragraph*{Le module} Lors d'un appel \Python, le nom du module n'est pas transmis. En revanche,  via la variable \verb|frame->f_code->co_filename|, on dispose du nom du fichier contenant le code exécuté à partir duquel on peut retrouver le nom du module. Par contre il s'agit d'une opération coûteuse car elle peut impliquer de nombreux calculs et appels au système de fichiers. Mais lors d'une définition en \Python il y a une relation forte entre le module et le fichier qui le définit\footnote{Un fichier correspond toujours à un seul et unique module qui est lui même entièrement défini dans le-dit fichier} et on peut donc s'en servir à la place du nom du module (quitte à résoudre son nom plus tard si nécessaire).

\paragraph*{La classe} L'un des éléments qui différencient une fonction d'une méthode est que une méthode prend explicitement une instance de la classe en premier argument et que par convention elle s'appelle \verb|self|. Pour récupérer le nom de la classe on peut donc vérifier si le premier élément s'appelle \verb|self| et s'il est une instance d'une classe, auquel cas l'objet dispose d'un attribut \verb|__class__| contenant un objet décrivant la classe, lui même disposant d'un attribut \verb|__name__| indiquant son nom.

\paragraph*{La méthode} Le nom de la méthode est indiqué via la variable \verb|frame->f_code->co_name|.

\subsection{Identification de la méthode appelée - Appel C}
À la différence des appels \Python, lors d'un appel \C (appel d'une fonction écrite en \C depuis un code \Python) le \emph{\gls{contexte d'exécution}} envoyé à la fonction de rappel ne correspond pas à celui de la fonction qui va être exécuté mais à celui de la fonction qui vient d'être exécutée, car s'agissant d'un appel \C le travail n'est pas effectué par l'interpréteur et aucune \verb|frame| n'est générée. En revanche un object décrivant la fonction \C à exécuter\footnote{Il s'agit d'un \verb|PyCFunctionObject*|, voir annexe \vref{app:PyCFunctionObject}} est passé à la fonction de rappel en plus de l'objet \verb|frame|

\paragraph*{Le module} Lors d'un appel C le nom du module auquel la fonction est rattaché est passé via la variable \verb|function->m_module| mais plusieurs deux cas de figures sont à considérer : 
\begin{itemize}
\item La fonction fait partie des builtin\footnote{Certaines fonctions sont toujours disponibles et ne sont rattachés à aucun module : \url{https://docs.python.org/2/library/functions.html}} de \Python alors cette variable vaut \verb|null| et le module associé est définit manuellement à \verb|__builtin__|
\item La fonction a été définie dans un module et la variable \verb|function->m_module| contient son nom.
\end{itemize}

\paragraph*{La classe} Si la fonction est en réalité une méthode d'une classe alors la variable\\ \verb|function->m_self| contient l'objet sur lequel l'appel de fonction se porte et on peut récupérer le nom de la classe comme lors d'un appel \Python.

\paragraph*{La méthode} Le nom de la méthode qui est utilisé dans le code \Python est accessible via la variable \verb|function->m_ml->ml_name|.
  
\subsection{Création du graphe d'appels}
\label{subsec:crea-graph-appel}
Le \gls{graphe d'appels} du programme est lui aussi construit à partir de la fonction de rappel, les événements de type \emph{sortie de fonction} sont utilisés pour détecter quand il faut retirer un élément de la pile et en rajouter un dans le graphe.

Le graphe est construit à partir de ses arcs, chaque appel représentant un arc partant de la fonction appelante et allant à la fonction appelée.

Ainsi, ces différents arcs sont représentés\footnote{Voir annexe \vref{app:graph_struct} pour la structure de données représentant un élément du graph} par la fonction appelante et la fonction appelées telles que définis dans la pile auxquelles on associe les même métriques qu'associées précédemment à la pile et un compteur représentant le nombre de fois où l'arc est présent\footnote{C'est à dire le nombre de fois où ce couple appelant/appelé a été rencontré dans le programme}.

\begin{note}[Gestion de la mémoire]
Afin de contrôler l'utilisation de la mémoire\footnote{Voir section \vref{sec:performances} pour plus de détails sur la gestion des performances} et éviter que celle-ci n'augmente indéfiniment lors de l'analyse de l'analyse d'un gros programme les différents éléments du graphe sont stockés dans une table de hachage et agrégés. Ainsi si le même appel de fonction survient plusieurs fois\footnote{Cela implique même appelant, même appelé et mêmes arguments de fonction si collectés pour les fonction en question} il n'y aura qu'une seule entrée dans la table de hachage et donc aucune consommation mémoire supplémentaire.
\end{note}

  \section{Arguments de fonction}
  \label{sec:fnargs}
L'une des fonctionnalités importantes de \Blackfire est sa faculté à récupérer dynamiquement les arguments de certaines fonctions\footnote{Il s'agit de l'une des fonctionnalités de la version payante, permettant entre autre de récupérer les requêtes \emph{SQL} effectuées}, cette liste de fonction étant définis dynamiquement et envoyé par l'agent lorsque le profil commence\footnote{Voir section \vref{subsec:comm-agent}}.

\subsection{Instrumenter les fonctions}
Cela implique d'être capable d'identifier dynamiquement si on doit récupérer les arguments de la fonction venant d'être appelée, et si oui de l'instrumenter. Pour cela, trois méthodes différentes ont été étudiées et testées avant qu'une soit retenue : 
\begin{itemize}
\item Résoudre le nom de chaque fonction appelée et regarder si il est dans la liste envoyée par l'agent
\item Remplacer, au démarrage de l'analyse, les fonctions à instrumenter par un décorateur
\item Charger les fonctions à instrumenter au démarrage l'analyse et stocker dans une table de hachage un identifiant unique et rapide à calculer
\end{itemize}

\subsubsection*{Résoudre le nom de la fonction}
Cette technique est la plus simple à mettre en œuvre mais aussi la plus coûteuse. En effet elle implique de devoir résoudre complètement le nom de la fonction courante dans tous les cas puis d'effectuer une recherche dans une table de hachage indexée par des chaînes de caractères. Et autant cette dernière opération est peu coûteuse autant ce n'est pas le cas pour la résolution du nom\footnote{Résoudre complètement le nom de la fonction implique de devoir résoudre le nom du module, voir section \vref{ident-python}}. Par conséquent cette technique a été rejetée.

\subsubsection*{Utiliser un décorateur}
L'objectif de cette technique est, lors de l'initialisation de \Blackfire, de charger les différentes fonctions instrumentées et de les remplacer par un décorateur écrit en \C ou en \Python qui se chargera d'en récupérer les arguments.

le principal avantage étant que c'est très efficace car cela ne nécessite aucun calcul supplémentaire lors de l'analyse pour savoir si il est nécessaire de récupérer les arguments de la fonction. En effet, même si cette technique a un coût non négligeable (il faut charger et instrumenter un nombre de modules possiblement grand) il est entièrement porté par l'initialisation et donc, à la différence de la technique précédente, ne transparaît pas dans le graphe généré.

En revanche il y a quelques problèmes. \\
Tout d'abord il est nécessaire d'avoir un décorateur différent par fonction instrumentée, c'est parfaitement faisable mais ça implique que le nombre de fonctions qu'il est possible d'instrumenter est limité en dur dans le code source de la sonde\footnote{Cela peut aussi rapidement doubler la taille du binaire, mais celle-ci étant faible, de l'ordre de 50ko, c'est peu important}.
 
Mais le vrai problème c'est que les fonctions sont appelées après le traitement de l'événement par la fonction de rappel et, par conséquent, le décorateur aurait à modifier la pile pour y intégrer les arguments après coup et cela rend le code plus difficile à maintenir.

\subsubsection*{Rechercher un identifiant unique dans une table de hachage}
Cette technique, à mis chemin entre les 2 précédentes, est celle qui a été retenue. L'objectif étant de récupérer les arguments des fonctions instrumentés lorsque la fonction de rappel quand traite l'événement associé tout en minimisant les calculs nécessaires.

Pour cela la première étape consiste, comme dans la seconde technique, à charger toutes les fonctions lors de l’initialisation sauf que cette fois-ci au lieu de remplacer la fonction en question par un décorateur on se contente d'en récupérer un identifiant unique facile à calculer\footnote{Pour une fonction \C se sera l'adresse de la structure décrivant la fonction \C à appelée, et pour un appel \Python l'adresse de la variable contenant le bytecode à exécuter}. Ensuite on utilise cet identifiant comme clef dans une table de hachage, la valeur associé à cette clef étant l'argument à récupérer\footnote{Voir annexe \vref{app:do_instrumentation} pour le code correspondant à l'instrumentation}.

Ensuite, dans la fonction de rappel il suffit de calculer l'identifiant correspondant à la fonction actuelle, de chercher si il est présent dans la table de hachage et si oui d'en récupérer les arguments demandés.

\begin{note}
Cette technique, tout comme la précédente, utilise le fait que \Python ne charge jamais 2 fois le même module et que par conséquent les adresses sont stables.
\end{note}

\begin{note}[Compatibilité Python 2/Python 3]
L'un des problèmes rencontrés lors de la mise en place de cette technique a été d'être compatible à la fois avec \Python 2 et \Python 3. En effet, dans \Python 3 le modèle objet a été entièrement réécrit afin de ne plus traiter différemment les classes définis en \C de celles définis en \Python. Ainsi les classes définis en \Python deviennent des types à part entière\footnote{Voir annexe \vref{app:compat-23} pour plus de détails}.
\end{note}

\subsection{Récupérer les arguments}
Récupérer les arguments peut être une tâche compliqué voir coûteuse dans certains cas et, quoi qu'il arrive, diffère entre un appel \C et un appel \Python.

\subsubsection*{Appel C}
Dans le cadre d'un appel \C on a pas accès au contexte de la fonction appelée\footnote{A vrai dire il n'est jamais créé} mais à celui de la fonction appelante. Par conséquent le seul moyen de récupérer les arguments est d'aller les lire directement dans la pile \Python\footnote{L'interpréteur \Python utilise une pile en interne pour gérer le contexte des fonctions - arguments, variables locales, valeur de retour etc... - tout comme le fait un programme \C compilé}.

Dans ce cas le contexte d'exécution donne accès à sa pile via plusieurs variables et notamment \verb|frame->f_valuestack| qui pointe juste après la dernière variable locale. Ainsi pour accéder aux différents arguments de la fonction \C appelée on peut utiliser\\ \verb|frame->f_valuestack + 0| pour le premier argument, \verb|frame->f_valuestack + 1| pour le second etc...

\begin{note}[Passage de paramètres]
Lors d'un appel de fonction \Python empile les différents paramètres de la fonction dans l'ordre dans lequel ils sont demandé. Ainsi le premier argument se retrouve dans la première case après la dernière locale, le second dans la seconde case et ainsi de suite.
\end{note}

\subsubsection*{Appel Python}
Dans le cadre d'un appel \Python on a accès au contexte d'exécution de la fonction appelée et via celui-ci aux variables locales de la fonction. Hors, lors d'un appel \Python les arguments de la fonction sont stockés dans les premières variables locales. Ainsi on peut récupérer le premier argument dans la première variable locale via \verb|frame->f_localsplus[0]|, le second argument dans la seconde variable locale via \verb|frame->f_localsplus[1]| etc...

Lors d'un appel Python il est aussi possible de récupérer un argument donné via son nom. Dans ce cas il est tout d'abord nécessaire de résoudre les variables locales et de créer le dictionnaire qui les associe à leur nom puis d'interroger ce dictionnaire pour récupérer l'argument que l'on désire.

\begin{note}
Par défaut le contexte d'exécution ne stocke pas le dictionnaire associant les variables locales à leur nom mais uniquement les informations requises pour le reconstruire (à savoir, la liste des noms des variables dans l'ordre dans lequel elles se trouvent dans la pile).
\end{note}

  \section{Détection des contours du programme}
      % problème du sitecustomize.py

L'un des problèmes rencontré a été de détecter correctement les contours du programme utilisateur afin de ne pas prendre en compte la phase d'initialisation de \Blackfire. En effet lorsque l'on utilise la technique d'instrumentation à l'aide du fichier \verb|sitecustmize.py|\footnote{Voir section \vref{sec:instru-pythonpath}} il y a une certaine quantité de code qui est exécuté avant même de compiler le programme utilisateur afin de charger et d'initialiser \Blackfire mais aussi d'effectuer diverses autres actions d'initialisation.

Pour cela lorsque que la fonction \verb|start()| et que la \gls{pile d'appels} existante est importée, on regarde chaque entrée pour savoir si le module \verb|site| est utilisé\footnote{Si c'est le cas alors au moins l'un des contextes concernent une fonction du module \verb|site| ou, si les noms des modules ne sont pas résolus, dont le fichier est \verb|site.py|}. Auquel cas la fonction de rappel entre dans un mode particulier où les arguments de fonction sont ignorés et aucune entrée n'est créée dans la table de hachage des profils.

Dans ce mode la sonde cherche à repérer l'appel de fonction correspondant au chargement du programme utilisateur. C'est à dire un appel dont la fonction appelée est \verb|<module>| et dont le nom du module, si résolu, est \verb|__main__| ou sinon dont le fichier correspond au fichier associé au module \verb|__main__|\footnote{Le fichier associé au module \verb?\_\_main\_\_? est renseigné au moment où ce dernier est chargé}.

\begin{note}
Il n'est pas possible de se contenter de surveiller la pile d'exécution et de dire que le programme utilisateur commence dès que celle-ci est à nouveau vide car elle peut se remplir et vider plusieurs fois avant que celui-ci ne commence réellement.
\end{note}

\begin{note}
Détecter correctement les contours du programme est d'autant plus important étant donné la manière dont le module \verb|site| est chargé puis exécuté certains modules peuvent être déchargé entre l'exécution du module site et l'exécution du code utilisateur, ce qui invalide le cache des méthodes\footnote{Voir section \vref{sec:gestion-graph-appels}}.
\end{note}

  \section{Dimension opcode}
    % utilisation de settrace 
    % à chaque ligne on compte le nombre d'opcodes de la ligne
    % => on n'a pas exactement le nombre d'ocodes executés car on peut utiliser des opérations inline
    % on ne peut pas utiliser le code donné par setprofile car il serait encore moins précis (boucle, conditions etc...)
    % => impact sur les performances à mesurer
    
Outre les dimensions traditionnelles (temps, temps cpu, mémoire consommée) une dimension donnant des informations sur la complexité du \gls{bytecode} exécuté est à l'étude et a été implémenté dans la sonde \Python.

En \Python le contexte d'exécution contient le \gls{bytecode} de la fonction à exécuté ou en cours d'exécution ainsi que les informations nécessaires pour retrouver dans cette liste les \gls{opcodes} précis qui doivent être interprétés. Mais il n'est pas possible d'utiliser les événements \emph{entrée de fonction} pour cela, en effet il est possible de compter tout le bytecode de la fonction mais ce n'est pas précis du tout car on manque les boucles et les conditions.

La technique retenue a été d'utiliser une autre fonction de rappel dédié à cet usage. Cette fonction étant enregistré via la méthode \verb|sys.settrace()|\footnote{\url{https://docs.python.org/2/library/sys.html#sys.settrace}} est appelée à chaque fois que l'interpréteur exécute une ligne \Python, ce qui est beaucoup plus précis même si il reste une certaine imprévision liée à l'utilisation de conditions en ligne et autres cas où plusieurs opérations sont effectuées sur la même ligne.

Afin de récupérer le bytecode de la ligne, la première étape consiste à décoder le champ du contexte d'exécution qui effectue l'association entre les lignes et le bytecode qui leur est associé\footnote{L'algorithme utilisé à été adapté à partir de celui implémenté dans le module dis, voir \url{} pour la fonction d'origine et l'annexe \vref{app:count_bytecode} pour l'implémentation effectuée}. Ensuite il suffit d'itérer sur le tableau d'opcodes entre les index calculés précédemment.

\begin{note}[Performances]
L'impact de cette dimension au niveau des performances reste a étudié, mais même si le nombre d'opération effectué dans la fonction de rappel est très limité, celle-ci est appelée un très grand nombre de fois ce qui fait que son impact n'est pas négligeable.
\end{note}

\begin{note}[Évolutions]
Actuellement la dimension indique le nombre d'\gls{opcodes} exécutés mais étant donné qu'ils n'ont pas tous le même coût (certains opcodes effectuent des opérations très simples comme une addition entre deux entiers, mais d'autres effectuent des opérations beaucoup plus lourde comme un appel de fonction ou le chargement d'un module), il serait certainement plus intéressant de les pondérer en fonction de celui-ci.
\end{note}

\begin{note}
Cette dimension n'est pas encore accessible à tout le monde et ne le sera peut être jamais. Il reste à étudier l'utilité des informations quelle apporte par rapport aux dimensions actuelle ainsi que par rapport à son impact au niveau des performances.
\end{note}

  \section{Performances}
  \label{sec:performances}
    % moyens mis en oeuvres pour gérer la perf
      % => free list (gestion de la mémoire)
      % => on tape cash dans la pile
      % => résolution au plus tard des noms de modules
      % => cache des nom de méthodes etc..
      % => hashtab efficace
      % => aggrégation
      
La sonde devant avoir un impact aussi faible que possible, son optimisation est l'un des points les plus importants et cela transparaît en de nombreux endroits.

\subsection{Structures de données}
L'implémentation de la pile et des tables de hachages utilisées ont été adaptées à partir de celle effectuée dans \emph{Yappi} à la différence que dans \Blackfire deux types de tables de hachages sont utilisée :
\begin{itemize}
\item La première pour utiliser des entiers en clef, la fonction de hachage étant celle de \emph{Yappi}
\item La seconde pour utiliser des chaînes de caractères en clef, la fonction de hachage étant \emph{MurmurHash3}\footnote{https://code.google.com/p/smhasher/wiki/MurmurHash}
\end{itemize}

Les tables de hachages numériques étant utilisées pour mettre en cache les définitions des méthodes et les identifiants des fonctions dont on récupère les arguments, et la table de hachage utilisant des chaînes de caractères servant à stocker le graphe.

\subsection{Gestion de la mémoire}
Allouer et désallouer de la mémoire via \verb|malloc| et \verb|free| fait appel au système d'exploitation et est très coûteux. Pour cette raison, la sonde \Python a été pensé pour minimiser au maximum ces appels dans la fonction de rappel, référant allouer la mémoire lors de son initialisation.

Pour cela plusieurs techniques sont utilisées : 
\begin{itemize}
\item Les tables de hachages sont pré-alloué avec des dimensions correspondant à celles d'un programme qu'on pourrait qualifié de taille classique : $2^{10}$ méthodes différentes, $2^{10}$ appels de fonction différents, $2^5$ méthodes dont les arguments de fonction sont récupérés.
\item La pile est elle aussi pré alloué avec 100 emplacements disponibles\footnote{Il s'agit de la limite de récursivité par défaut de l'interpréteur \Python}.
\item Le concept de \emph{freelist} de \emph{Yappi} a été réutilisé et utilisé pour les méthodes, les entrées de la pile et les entrées du graphe.
\end{itemize}

\begin{note}[freelist]
Afin d'éviter d'avoir à allouer de la mémoire trop souvent, \emph{Yappi} utilise ce qu'il appelle des \emph{freelist}, à savoir des listes de structures pré-allouées et pouvant être utilisées. Ainsi, par exemple, lorsque qu'une nouvelle méthode est rencontré, au lieu d'allouer la mémoire correspondant à la structure \verb|_method| on demande à la \emph{freelist} un élément disponible. Et lorsque l'élément n'est plus utilisé (par exemple avec les entrées de la pile), l'élément est retourné à sa liste. De cette manière il n'y a que rarement besoins d'allouer ou de désallouer de la mémoire\footnote{Si jamais la \emph{freelist} ne dispose d'aucun élément de disponible elle s'agrandit toute seule et double sa taille}.
\end{note}

\subsection{Résolution du nom des modules}
Résoudre le nom des modules est une opération coûteuse impliquant entre autre des appels au système de fichier. Pour cette raison la fonction de rappel ne le résout mais préfère travailler avec le nom des fichiers. En revanche il n'est pas très commode d'avoir les noms des fichiers dans le graphe et il est donc nécessaire de résoudre ces noms au dernier moment, juste avant d'envoyer les données à l'agent.

\subsection{Agrégation du graphe}
Comme évoqué précédemment dans la section \vref{subsec:crea-graph-appel}, afin de limiter la consommation mémoire de la sonde lors de l'analyse d'un programme effectuant de nombreux appels de fonction, les différents éléments du graphe sont agrégés. Ainsi un même arc n’apparaît pas deux fois dans la table de hachage et la taille de cette dernière a tendance à se stabiliser au bout d'un moment.

  \section{Évolutions}
  	% Multi threading (expliquer comment faire, en s'inspirant de yappi, et les problèmes restants: comment on représente ça dans notre graph? on ajoute le numéro du thread dans chaque noeud?)
  	% Dimension opcode (définir utilité, puis préciser la dimension avec ajout de poids sur les opcodes) peut valoir le coup d'expliquer comment la dimension fonctionne
  	% Fichier de configuration 
  	% Intégration dans blackfire run pour éviter d'avoir à définir le PYTHONPATH
  	
La sonde \Python est actuellement en version alpha et est parfaitement fonctionnelle mais il reste toujours un certain nombre de points à étudier.

\begin{itemize}
\item \textbf{La distribution}\;~ Actuellement la sonde de \Blackfire est \gls{closed source} et il faut donc distribuer une version binaire. En \Python cela peut être réalisé facilement en utilisant la plateforme \emph{PyPI}\footnote{https://pypi.python.org/} et le format \emph{wheel}\footnote{https://pypi.python.org/pypi/wheel/0.24.0}. Reste à régler la génération de ces paquets pour les différentes versions de \Python et les différents systèmes supportés.
\item \textbf{Multi threading}\;~ Le multi threading est très présent en \Python et il serait intéressant de le supporter. Il est possible de s'inspirer de \emph{Yappi} pour l'instrumentation automatique des threads mais il reste à définir comment représenter ceux-ci dans le graphe. Une solution pouvant être d'ajouter à toutes les fonctions un argument fictif\footnote{On pourrait aussi imaginer de préfixer ou de suffixer le nom de la méthode comme pour les appels récursifs} représentant le thread.
\item \textbf{Fichier de configuration}\;~ La sonde \PHP utilise un fichier de configuration en plus des variables d'environnement. Il pourrait être utile de faire la même chose avec la probe \Python. Par contre il reste à déterminer où positionner ce fichier car, contrairement à \PHP, \Python n'en n'utilise aucun.
\item \textbf{PYTHONPATH}\;~ Il est assez fastidieux de devoir renseigner le \verb|PYTHONPATH| à chaque fois que l'on veut analyser un programme depuis la ligne de commande. Il pourrait être intéressant que celui-ci soit automatiquement définit par la commande \verb|blackfire run| lorsqu'elle est utilisée.
\end{itemize}
  	
% -----------------------------------------------------------------------------------  	
  	
%  @todo inséré graphe "UML" ici : http://yuml.me/edit/b8c15b3b (ou en annexe ?) 
%   
%  Les deux implémentations ont sensiblement la même structure et sont découpés en 7 modules. La différence étant que l'implémentation \C introduit un nouveau module qui remplace une partie de \mintinline{python}{blackfire.profiler}.
%  \begin{itemize}
%    \item \mintinline{python}{blackfire} définit l'interface du programme, c'est lui qui est documenté et qui doit être utilisé par les développeurs extérieurs.
%    \item \mintinline{python}{blackfire.wsgi_wrapper} définit une classe servant de \gls{wrapper} \gls{WSGI} et un décorateur permettant de l'utiliser simplement.
%    \item \mintinline{python}{blackfire.config} définit les fonctions nécessaires à la configuration de Blackfire (traitement de la configuration, initialisation de la sonde...)
%    \item \mintinline{python}{blackfire.probe} définit la la classe \mintinline{python}{BlackfireProbe} et implémente le protocole utilisé pour communiquer avec l'agent. Elle définit aussi une interface qui peut être utilisé par le développeur pour instrumenter son code manuellement.
%    \item \mintinline{python}{blackfire.profiler} définit la classe \mintinline{python}{Profiler} qui est en charge de collecter les données (métriques et \gls{graphe d'appels}).
%    \item \mintinline{python}{blackfire.memory_collector} définit des fonctions permettant de récupérer la consommation mémoire du programme.
%    \item \mintinline{python}{blackfire.dead_sockets_pool} définit une classe permettant de gérer les sockets devant être libérés.
%  \end{itemize}
